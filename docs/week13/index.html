<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <meta name="date" content="" />
      <title>Week 13 - Machine Learning and facial/gesture recognition
for UI</title>
      <link rel="stylesheet" href="../css/../css/cui.css" />

      <meta property="og:title" content="Week 13 - Machine Learning and
facial/gesture recognition for UI" />
            <meta property="og:description" content="This week we review
facial and image recognition, its use for interface design, and privacy
issues." />
                  <meta property="og:type" content="article" />
  </head>
  <body>
      <header> <nav>
    <p><a href="..">←home</a><br />
</nav> </footer>
      <h1>Week 13 - Machine Learning and facial/gesture recognition for
UI</h1>
      <p><em>Date: 2025-04-16</em></p>
      <h2 id="overview">Overview</h2>
      <ul>
      <li>check in</li>
      <li>presentations: Topics on Accessibility</li>
      <li>Facial Recognition as UI</li>
      <li>Gesture Recognition as UI</li>
      <li>Coding examples with Machine Learning and Teachable
      Machine</li>
      <li>Final Project requirements</li>
      </ul>
      <h2 id="accesibility-presentations">Accesibility
      presentations</h2>
      <p>How the blind use technology to see the world</p>
      <p>Austin Seraphin - <a
      href="https://www.youtube.com/watch?v=0EQOZRIA-nA">video</a></p>
      <p>Austin’s <a href="http://austinseraphin.net/">website</a>.</p>
      <p>Voice User Interfaces - Austin was on the committee for
      accessibility of these interactive fiction games who has posted a
      <a href="http://accessibility.iftechfoundation.org/">report</a> on
      their research.</p>
      <h2 id="facial-recognition">Facial Recognition</h2>
      <figure>
      <img src="../images/facial.png"
      alt="facial recognition data points tracking" />
      <figcaption aria-hidden="true">facial recognition data points
      tracking</figcaption>
      </figure>
      <p>How does it work? Five step process:</p>
      <ol type="1">
      <li>Facial detection / tracking</li>
      <li>Facial alignment</li>
      <li>Feature extraction</li>
      <li>Feature matching</li>
      <li>Facial recogntion</li>
      </ol>
      <p><img src="../images/facerecognition.webp"
      alt="Facial recognition in applications" /><br />
      Facial recognition in application interfaces</p>
      <h3
      id="new-facial-recognition-and-machine-learning-interfaces">New
      facial recognition and machine learning interfaces</h3>
      <p>Project Euphonia - <em>Helping everyone be understood</em> - <a
      href="https://www.youtube.com/watch?v=OAdegPmkK-o">video</a> - <a
      href="https://sites.google.com/view/project-euphonia/">link</a> to
      project</p>
      <h1 id="facial-recognition---ethical-concerns">Facial Recognition
      - ethical concerns</h1>
      <p>What Facial Recognition Steals From Us - <a
      href="https://www.youtube.com/watch?v=cc0dqW2HCRc">video</a></p>
      <blockquote>
      <p>Human faces evolved to be highly distinctive; it’s helpful to
      be able to recognize individual members of one’s social group and
      quickly identify strangers, and that hasn’t changed for hundreds
      of thousands of years. Then in just the past five years, the
      meaning of the human face has quietly but seismically shifted.
      That’s because researchers at Facebook, Google, and other
      institutions have nearly perfected techniques for automated facial
      recognition. The result of that research is that your face isn’t
      just a unique part of your body anymore, it’s biometric data that
      can be copied an infinite number of times and stored forever. In
      this video, we explain how facial recognition technology works,
      where it came from, and what’s at stake. –<em>ReCode, Vox
      Media</em></p>
      </blockquote>
      <h2 id="reading-on-ethical-issues-of-facial-recognition">Reading
      on ethical issues of facial recognition</h2>
      <p><img src="../images/shopper.jpg"
      alt="facial recognition in store" /><br />
      image modified by ACLU, original by colorblindPicaso on Flickr</p>
      <ul>
      <li><a
      href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2439866">Obscurity
      and Privacy</a> by Evan Seligner and Woodrow Hartzog, from
      Routledge Companion to Philosophy of Technology (Joseph Pitt &amp;
      Ashley Shew, eds., 2014 Forthcoming)<br />
      </li>
      <li><a
      href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3305312">Face
      Recognition and Privacy in the Age of Augmented Reality</a> by
      Alessandro Acquisit, Ralph Gross and Frederic Stutzman in the
      Journal of Privacy and Confidentiality, 6(2), 1, 2014</li>
      <li><a
      href="https://www.washingtonpost.com/technology/2019/07/07/fbi-ice-find-state-drivers-license-photos-are-gold-mine-facial-recognition-searches/">FBI
      and ICE Find State Driver’s License Photos Are a Gold Mine for
      Facial Recognition Searches</a> in Technology, The Washington
      Post, September 7, 2019</li>
      <li><a
      href="https://www.aclu.org/blog/privacy-technology/surveillance-technologies/are-stores-you-shop-secretly-using-face">Are
      Stores You Shop at Secretly Using Face Recognition on You?</a> by
      Jenna Bitar and Jay Stanley, ACLU Blog, March 26, 2018</li>
      <li><a
      href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html">The
      Secretive Company That Might End Privacy as We Know It</a> by
      Kashmir Hill, The New York Times, January 18, 2020</li>
      </ul>
      <h1 id="examples-of-facial-recognition-ui">Examples of Facial
      Recognition UI</h1>
      <ul>
      <li>How Facial Recognition works at CaixaBank ATMS - <a
      href="https://www.youtube.com/watch?v=fLRsjktcN_k">video</a></li>
      </ul>
      <h1
      id="coding-examples-with-machine-learning-and-teachable-machine">Coding
      examples with Machine Learning and Teachable Machine</h1>
      <p><a href="https://teachablemachine.withgoogle.com/">Teachable
      Machine</a></p>
      <h3 id="training-an-image-classification-model">Training an Image
      Classification Model</h3>
      <ol type="1">
      <li>Collect Data</li>
      </ol>
      <ul>
      <li>Have 2 kinds of images of something</li>
      <li>Label those images - (these are called “classes”)</li>
      <li>how many? - experiment. maybe 25 - 50 images per
      category.</li>
      </ul>
      <ol start="2" type="1">
      <li>Click <em>Train Model</em> and <strong>Do not switch
      tabs</strong> as it is training in the browser live!</li>
      </ol>
      <ul>
      <li>This image classification is using MobileNet and a pretrained
      model (of a Convolutional Neural Network) to do Transfer
      Learning</li>
      </ul>
      <ol start="3" type="1">
      <li>When finished, test it. You can add more classes if you like
      (such as additional poses, or additional images).</li>
      <li>It’s good? Now we must save by clicking to <em>Export
      model</em>. Choose Tensorflow.js and choose to export to the
      Cloud. (In the future, if you don’t want to upload your model to
      Google’s server you could save locally). You will get a URL and a
      permanent webpage to use/test/debug/change your model.</li>
      </ol>
      <h3 id="example-starter-code">Example starter code</h3>
      <p><a
      href="https://editor.p5js.org/2sman/sketches/rtSl0Xmkq">link</a></p>
      <ol type="1">
      <li>Change your model url!</li>
      <li>Edit your triggers.js file!</li>
      </ol>
      <h3 id="resources-for-teachable-machine">Resources for Teachable
      Machine</h3>
      <ul>
      <li>Sample javascript code on <a
      href="https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image">github</a></li>
      <li>Intro to Teachable Machine for Image Classification - <a
      href="https://www.youtube.com/watch?v=kwcillcWOg0">video</a> on
      The Coding Train</li>
      <li>Tutorial on making a “Snake game” using gesture recognition -
      <a href="https://www.youtube.com/watch?v=UPgxnGC8oBU">video</a> on
      The Coding Train</li>
      </ul>
      <h2 id="final-project-speculative-interfaces">Final Project:
      Speculative Interfaces</h2>
      <h5 id="requirements">requirements</h5>
      <blockquote>
      <p>“Where typical design takes a look at small issues, speculative
      design broadens the scope and tries to tackle the biggest issues
      in society.” –Anthony Dunne and Fiona Raby, <em>Speculative
      Everything: Design, Fiction, and Social Dreaming</em></p>
      </blockquote>
      <p>Rather than look just at issues of today, speculative design
      thinking asks “How can we address future challenges with
      design?”</p>
      <p>Propose a speculative user interface for an application.
      Throughout the course of the project you will propose a concept
      idea and design brief, create prototypes, test, and document and
      present.</p>
      <p>Your idea can be practical or fanciful, surprising or
      challenging. It is an experimental interface, pointing forward to
      a new future.</p>
      <p>Keep in mind our design and prototyping processes we’ve covered
      throughout the semester. You may have to improvise your own new
      approach for your speculative interface.</p>
      <p>Consider our readings and learning from throughout the semester
      including but not limited to: the early history of early interface
      design, interface metaphors of the desktop, ergonomics, graphical
      interfaces, accessibility, voice control, speculative
      thinking.</p>
      <p>For next week, turn in a Design Brief including: - a. concept
      stated in a short paragraph. How does it work? What is it for? -
      b. list of sources - ideas, writing, concepts that are informing
      your design work (can also include science fiction, games,
      articles, movies) - c. image references from these sources aka
      ‘mood board’ or inspiration - d. sketches (paper/pen and/or
      digital) - e. flowchart of interface - textual and/or visual -
      f. list of resources (starter code, library, underlying
      technology)</p>
      <h3 id="references">References</h3>
      <ul>
      <li>This is Not My Beautiful Home - <a
      href="http://continentcontinent.cc/index.php/continent/article/view/334">essay</a>
      by Everest Pipkin</li>
      <li>What is Speculative Design? - <a
      href="https://www.youtube.com/watch?v=X0MBJ1UxpZ8">video</a></li>
      <li>Pointing to the future of UI - <a
      href="https://www.youtube.com/watch?v=b6YTQJVzwlI">video</a></li>
      <li><em>Her</em> movie - Alien Child - speculative video game - <a
      href="https://www.youtube.com/watch?v=XAqedT9mukY">video</a></li>
      <li>Interfacing with devices through silent speech - <a
      href="https://www.youtube.com/watch?v=RuUSc53Xpeg">video</a></li>
      <li>Dynamicland Hardware Field trip - <a
      href="https://www.youtube.com/watch?v=OQpr454yhvM">video</a></li>
      <li>Virtual Reality Training for Operators - <a
      href="https://www.youtube.com/watch?v=KYK6wuFaES8">video</a></li>
      </ul>
      <footer> <hr>

<p><em><a href="https://github.com/lee2sman/cui_spring2025">This site</a> is built using <a href="https://tildegit.org/exquisitecorp/panblog">panblog</a>. Site design by Lee Tusman (c) 2025.</em></p>

<p><em>All course content, unless otherwise credited, is by Lee Tusman (c) 2025 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">CC BY-NC-SA</a>.</em></p>

<p><a href="#">↑top</a></p> </footer>
  </body>
</html>
