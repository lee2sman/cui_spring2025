<!DOCTYPE html>
<html lang="en">
  <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <meta name="date" content="" />
      <title>Week 13 - Building Speculative Interfaces</title>
      <link rel="stylesheet" href="../css/../css/main.css" />

      <meta property="og:title" content="Week 13 - Building Speculative
Interfaces" />
                  <meta property="og:type" content="article" />
  </head>
  <body>
      <header> <nav>
    <p><a href="..">←home</a><br />
</nav> </footer>
      <h1>Week 13 - Building Speculative Interfaces</h1>
      <p><em>Date: 2025-04-22</em></p>
      <p><img src="../images/sensor.jpg"
      alt="Human body representations - 2d skeleton model and 3d pictorial representation" />
      <em><a
      href="https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2015.00028/full">from
      A Review of Human Activity Recognition Methods, from Frontiers in
      Robotics and AI</a></em></p>
      <h2 id="speculative-interfaces">Speculative interfaces</h2>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/33Raqx9sFbo?si=Kl8W9tVcZbefQELt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
      </iframe>
      <p><em>Minority Report (2002 film)</em></p>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/h8idqFM1e2Y?si=DfaYCTkaSeX-n6EO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
      </iframe>
      <p><em>Recent promo Video from Oblong (Underkoffler was the lead
      for designing the speculative system for Minority Report)</em></p>
      <h3 id="paper-signals">Paper Signals</h3>
      <iframe src="https://lh3.googleusercontent.com/pcw8OkRuJDsajfhv-A_Q7Q83b8qpQ8z9PfN1yvw1ZXCgHRRiHUHMz3CnB-tn7PZ9JWWk-snrpYfCYnE6N6xItDO4jH0i" title="Paper Signals">
      </iframe>
      <blockquote>
      <p><a href="https://papersignals.withgoogle.com/">Paper
      Signals</a> is an experiment that explores how physical things can
      be controlled with voice. <em>–source: <a
      href="https://experiments.withgoogle.com/paper-signals">Experiments
      with Google</a></em></p>
      </blockquote>
      <h3 id="project-oasis">Project Oasis</h3>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/yyjN_ZwJr8Y?si=08xkNcfB-MavD58S" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
      </iframe>
      <blockquote>
      <p><a href="https://experiments.withgoogle.com/oasis">Project
      Oasis</a> is a self-sustaining plant ecosystem that reflects
      outside weather patterns by creating clouds, rain, and light
      inside a box. You can talk to it using the Google Assistant and
      ask it to create certain conditions or show you the weather in a
      specific place. This experiment expands our conversation with
      technology and the natural world.</p>
      </blockquote>
      <h3 id="project-conjure">Project Conjure</h3>
      <iframe src="https://dam-prod.media.mit.edu/thumb/2018/10/19/marioUp.gif.1400x1400.gif" title="Project Conjure">
      </iframe>
      <blockquote>
      <p>A recent focus of our lab has been making use of Tangible
      Displays and Body Object Space to develop new assistive
      technologies. As a test case, we prototyped the Mario
      side-scrolling game for visually impaired users, using body
      movement analogies to control Mario in the game. <em>–Kallirroi
      Retzepi at MIT Media Lab</em></p>
      </blockquote>
      <p><a
      href="https://www.media.mit.edu/projects/conjugate/overview/">link</a></p>
      <h3 id="whats-america-listening-to">What’s America Listening
      To?</h3>
      <iframe src="https://dam-prod.media.mit.edu/thumb/2017/09/28/giphy.gif.1400x1400.gif">
      </iframe>
      <blockquote>
      <p>We built an immersive <a
      href="https://www.media.mit.edu/projects/what-s-america-listening-to/overview/">talk
      radio</a> experience, where you can fly over America and select
      talk-radio stations to listen to live. The experience gives you an
      astronaut’s view of the Earth, while at the same time allowing you
      to be immersed in multiple channels of talk-radio. While listening
      to stations, we realized that there were many subjects that were
      heavily discussed in talk-radio shows which we had never heard of.
      We also overlayed information about congressional districts and
      how they voted in the 2008, 2012, and 2016 election. By selecting
      a station, you could also see who the congress-people for that
      district are.</p>
      </blockquote>
      <h3 id="click-here">Click Here</h3>
      <figure>
      <img src="../images/clickhere.jpg"
      alt="ClickHere chrome extension" />
      <figcaption aria-hidden="true">ClickHere chrome
      extension</figcaption>
      </figure>
      <blockquote>
      <p>ClickHere is a Chrome plugin that automatically transforms a
      web page to an abstract attentional tapestry. The project takes on
      an interface critique standpoint by asking the following
      questions: how do our habitual online spaces transform themselves
      when reduced to only a few building blocks? More specifically,
      what does a browser window look like when all attention-hungry
      elements are emphasized?</p>
      </blockquote>
      <p>available in the Chrome Extensions - <a
      href="https://chrome.google.com/webstore/detail/clickhere/jfaffmmgpchfnghgbengkgnonbndkdpg">chrome
      web store</a></p>
      <p><a href="https://github.com/Kallirroi/clickHere">code</a></p>
      <p>– Kallirroi Retzepi</p>
      <h3 id="resources">Resources</h3>
      <ul>
      <li>Pose Recognition tutorial - <a
      href="https://medium.com/@warronbebster/teachable-machine-tutorial-head-tilt-f4f6116f491">link</a></li>
      </ul>
      <h3
      id="queering-our-interfaces-push-notifications-expressing-promiscuity">Queering
      Our Interfaces: Push-Notifications Expressing Promiscuity</h3>
      <p>by Elena Lee Gold</p>
      <ul>
      <li>Prototypes - <a
      href="https://youtu.be/TrLRxfo9WXI?t=1110">video</a> <em>–starting
      at 18:30</em></li>
      </ul>
      <h3 id="brain-computer-interfaces">Brain-Computer Interfaces</h3>
      <p>by Sean Montgomery (Founder EmotiBit), Conor Russomanno (CEO
      and Co-Founder Open BCI), Heidi Boisvert (Director of Emerging
      Media Technology at CUNY), Guillermo Bernal (MIT Media Lab, Fluid
      Interfaces)</p>
      <ul>
      <li>Panel - <a
      href="https://www.youtube.com/watch?v=EeMNgqVlqS0&amp;list=PLgN5oR6iaEy4YzgD8FFNkOxvkL0FUwL4C&amp;index=14">video</a></li>
      </ul>
      <blockquote>
      <p>Electrical and chemical signals are constantly traveling
      throughout our brains and bodies, carrying sensations, thoughts,
      emotions and our reactions to the world around us. Studying these
      signals and how they are altered by external stimuli and internal
      contexts gives us a window into ourselves and how we can enhance
      our health, well-being, and capabilities in the 21st century.
      Using open-source tools like Processing, EmotiBit, and OpenBCI and
      XTH we will discuss how sensing signals from the body can be used
      in research, education, art, DIY projects and, perhaps, to alter
      the future of human cognition.</p>
      </blockquote>
      <h2 id="intro-to-image-classification">Intro to Image
      Classification</h2>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/OcycT1Jwsns?si=HD42-yN-u5SXjPoh" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
      </iframe>
      <p><em>Intro: How Computer Vision Works - Google</em></p>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/Cgxsv1riJhI?si=9mj4E_GlSCWCrnPE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
      </iframe>
      <p><em>Object Detection: How computers learn to recognize objects
      instantly | Joseph Redmon </em></p>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/taC5pMCm70U?si=GWPm-1Or__uQB1u5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
      </iframe>
      <p><em>Image classification vs object detection</em></p>
      <h2 id="training-an-image-classification-model">Training an Image
      Classification Model</h2>
      <p><a href="https://teachablemachine.withgoogle.com/">Teachable
      Machine</a></p>
      <p><a
      href="https://glitch.com/edit/#!/teachable-hands-on-head?path=README.md%3A1%3A0">Lee’s
      Hands-on-Head demo of image recognition/classification</a></p>
      <ol type="1">
      <li>Collect Data</li>
      </ol>
      <ul>
      <li>Have 2 kinds of images of something</li>
      <li>Label those images - (these are called “classes”)</li>
      <li>how many? - experiment. maybe 25 - 50 images per
      category.</li>
      </ul>
      <ol start="2" type="1">
      <li>Click <em>Train Model</em> and <strong>Do not switch
      tabs</strong> as it is training in the browser live!</li>
      </ol>
      <ul>
      <li>This image classification is using MobileNet and a pretrained
      model (of a Convolutional Neural Network) to do Transfer
      Learning</li>
      </ul>
      <ol start="3" type="1">
      <li>When finished, test it. You can add more classes if you like
      (such as additional poses, or additional images).</li>
      <li>It’s good? Now we must save by clicking to <em>Export
      model</em>. Choose Tensorflow.js and choose to export to the
      Cloud. (In the future, if you don’t want to upload your model to
      Google’s server you could save locally). You will get a URL and a
      permanent webpage to use/test/debug/change your model.</li>
      </ol>
      <h3 id="example-starter-code">Example starter code</h3>
      <p><a
      href="https://editor.p5js.org/2sman/sketches/rtSl0Xmkq">link</a></p>
      <ol type="1">
      <li>Change your model url!</li>
      <li>Edit your triggers.js file!</li>
      </ol>
      <h3 id="resources-for-teachable-machine">Resources for Teachable
      Machine</h3>
      <ul>
      <li>Sample javascript code on <a
      href="https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image">github</a></li>
      <li>Intro to Teachable Machine for Image Classification - <a
      href="https://www.youtube.com/watch?v=kwcillcWOg0">video</a> on
      The Coding Train</li>
      <li>Tutorial on making a “Snake game” using gesture recognition -
      <a href="https://www.youtube.com/watch?v=UPgxnGC8oBU">video</a> on
      The Coding Train</li>
      </ul>
      <h2 id="final-project-speculative-interfaces">Final Project:
      Speculative Interfaces</h2>
      <h5 id="requirements">requirements</h5>
      <blockquote>
      <p>“Where typical design takes a look at small issues, speculative
      design broadens the scope and tries to tackle the biggest issues
      in society.” –Anthony Dunne and Fiona Raby, <em>Speculative
      Everything: Design, Fiction, and Social Dreaming</em></p>
      </blockquote>
      <p>Rather than look just at issues of today, speculative design
      thinking asks “How can we address future challenges with
      design?”</p>
      <p>Propose a speculative user interface for an application.
      Throughout the course of the project you will propose a concept
      idea and design brief, create prototypes, test, and document and
      present.</p>
      <p>Your idea can be practical or fanciful, surprising or
      challenging. It is an experimental interface, pointing forward to
      a new future.</p>
      <p>Keep in mind our design and prototyping processes we’ve covered
      throughout the semester. You may have to improvise your own new
      approach for your speculative interface.</p>
      <p>Consider our readings and learning from throughout the semester
      including but not limited to: the early history of early interface
      design, interface metaphors of the desktop, ergonomics, graphical
      interfaces, accessibility, voice control, speculative
      thinking.</p>
      <p>For next week, turn in a Design Brief including: - a. concept
      stated in a short paragraph. How does it work? What is it for? -
      b. list of sources - ideas, writing, concepts that are informing
      your design work (can also include science fiction, games,
      articles, movies) - c. image references from these sources aka
      ‘mood board’ or inspiration - d. sketches (paper/pen and/or
      digital) - e. flowchart of interface - textual and/or visual -
      f. list of resources (starter code, library, underlying
      technology)</p>
      <h6 id="references">References</h6>
      <ul>
      <li>This is Not My Beautiful Home - <a
      href="http://continentcontinent.cc/index.php/continent/article/view/334">essay</a>
      by Everest Pipkin</li>
      <li>What is Speculative Design? - <a
      href="https://www.youtube.com/watch?v=X0MBJ1UxpZ8">video</a></li>
      <li>Pointing to the future of UI - <a
      href="https://www.youtube.com/watch?v=b6YTQJVzwlI">video</a></li>
      <li><em>Her</em> movie - Alien Child - speculative video game - <a
      href="https://www.youtube.com/watch?v=XAqedT9mukY">video</a></li>
      <li>Interfacing with devices through silent speech - <a
      href="https://www.youtube.com/watch?v=RuUSc53Xpeg">video</a></li>
      <li>Dynamicland Hardware Field trip - <a
      href="https://www.youtube.com/watch?v=OQpr454yhvM">video</a></li>
      <li>Virtual Reality Training for Operators - <a
      href="https://www.youtube.com/watch?v=KYK6wuFaES8">video</a></li>
      </ul>
      <h3 id="final-deliverables">Final deliverables</h3>
      <ol type="1">
      <li>Title</li>
      <li>Concept Description of the interface</li>
      <li>Practical description of how it works</li>
      <li>Video OR images with text captions demonstrating a
      step-by-step walkthrough of your interface</li>
      </ol>
      <footer> <hr>

<p><em><a href="https://github.com/lee2sman/cui_spring2025">This site</a> is built using <a href="https://tildegit.org/exquisitecorp/panblog">panblog</a>. Site design by Lee Tusman (c) 2025.</em></p>

<p><em>All course content, unless otherwise credited, is by Lee Tusman (c) 2025 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">CC BY-NC-SA</a>.</em></p>

<p><a href="#">↑top</a></p> </footer>
  </body>
</html>
