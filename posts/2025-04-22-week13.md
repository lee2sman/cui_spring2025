---
title: Week 13 - Building Speculative Interfaces
---

![Human body representations - 2d skeleton model and 3d pictorial representation](sensor.jpg)
*[from A Review of Human Activity Recognition Methods, from Frontiers in Robotics and AI](https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2015.00028/full)*

## Speculative interfaces

<iframe width="560" height="315" src="https://www.youtube.com/embed/33Raqx9sFbo?si=Kl8W9tVcZbefQELt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
*Minority Report (2002 film)*

<iframe width="560" height="315" src="https://www.youtube.com/embed/h8idqFM1e2Y?si=DfaYCTkaSeX-n6EO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

*Recent promo Video from Oblong (Underkoffler was the lead for designing the speculative system for Minority Report)*

### Paper Signals

<iframe src="https://lh3.googleusercontent.com/pcw8OkRuJDsajfhv-A_Q7Q83b8qpQ8z9PfN1yvw1ZXCgHRRiHUHMz3CnB-tn7PZ9JWWk-snrpYfCYnE6N6xItDO4jH0i" title="Paper Signals"></iframe>

> [Paper Signals](https://papersignals.withgoogle.com/) is an experiment that explores how physical things can be controlled with voice. *--source: [Experiments with Google](https://experiments.withgoogle.com/paper-signals)*

### Project Oasis

<iframe width="560" height="315" src="https://www.youtube.com/embed/yyjN_ZwJr8Y?si=08xkNcfB-MavD58S" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

> [Project Oasis](https://experiments.withgoogle.com/oasis) is a self-sustaining plant ecosystem that reflects outside weather patterns by creating clouds, rain, and light inside a box. You can talk to it using the Google Assistant and ask it to create certain conditions or show you the weather in a specific place. This experiment expands our conversation with technology and the natural world.

### Project Conjure

<iframe src="https://dam-prod.media.mit.edu/thumb/2018/10/19/marioUp.gif.1400x1400.gif" title="Project Conjure"></iframe>

> A recent focus of our lab has been making use of Tangible Displays and Body Object Space to develop new assistive technologies. As a test case, we prototyped the Mario side-scrolling game for visually impaired users, using body movement analogies to control Mario in the game. *--Kallirroi Retzepi at MIT Media Lab*

[link](https://www.media.mit.edu/projects/conjugate/overview/)  

### What's America Listening To?

<iframe src="https://dam-prod.media.mit.edu/thumb/2017/09/28/giphy.gif.1400x1400.gif"></iframe>

> We built an immersive [talk radio](https://www.media.mit.edu/projects/what-s-america-listening-to/overview/) experience, where you can fly over America and select talk-radio stations to listen to live.  The experience gives you an astronaut's view of the Earth, while at the same time allowing you to be immersed in multiple channels of talk-radio. While listening to stations, we realized that there were many subjects that were heavily discussed in talk-radio shows which we had never heard of.
> We also overlayed information about congressional districts and how they voted in the 2008, 2012, and 2016 election. By selecting a station, you could also see who the congress-people for that district are.

### Click Here

![ClickHere chrome extension](clickhere.jpg)

> ClickHere is a Chrome plugin that automatically transforms a web page to an abstract attentional tapestry. The project takes on an interface critique standpoint by asking the following questions: how do our habitual online spaces transform themselves when reduced to only a few building blocks? More specifically, what does a browser window look like when all attention-hungry elements are emphasized?

available in the Chrome Extensions - [chrome web store](https://chrome.google.com/webstore/detail/clickhere/jfaffmmgpchfnghgbengkgnonbndkdpg)

[code](https://github.com/Kallirroi/clickHere)

-- Kallirroi Retzepi

### Resources

- Pose Recognition tutorial - [link](https://medium.com/@warronbebster/teachable-machine-tutorial-head-tilt-f4f6116f491)

### Queering Our Interfaces: Push-Notifications Expressing Promiscuity

by Elena Lee Gold 

- Prototypes - [video](https://youtu.be/TrLRxfo9WXI?t=1110) 
*--starting at 18:30*

### Brain-Computer Interfaces

by Sean Montgomery (Founder EmotiBit), Conor Russomanno (CEO and Co-Founder Open BCI), Heidi Boisvert (Director of Emerging Media Technology at CUNY), Guillermo Bernal (MIT Media Lab, Fluid Interfaces)

- Panel - [video](https://www.youtube.com/watch?v=EeMNgqVlqS0&list=PLgN5oR6iaEy4YzgD8FFNkOxvkL0FUwL4C&index=14)

> Electrical and chemical signals are constantly traveling throughout our brains and bodies, carrying sensations, thoughts, emotions and our reactions to the world around us. Studying these signals and how they are altered by external stimuli and internal contexts gives us a window into ourselves and how we can enhance our health, well-being, and capabilities in the 21st century. Using open-source tools like Processing, EmotiBit, and OpenBCI and XTH we will discuss how sensing signals from the body can be used in research, education, art, DIY projects and, perhaps, to alter the future of human cognition.

## Intro to Image Classification

<iframe width="560" height="315" src="https://www.youtube.com/embed/OcycT1Jwsns?si=HD42-yN-u5SXjPoh" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

*Intro: How Computer Vision Works - Google*

<iframe width="560" height="315" src="https://www.youtube.com/embed/Cgxsv1riJhI?si=9mj4E_GlSCWCrnPE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

*Object Detection: How computers learn to recognize objects instantly | Joseph Redmon *

<iframe width="560" height="315" src="https://www.youtube.com/embed/taC5pMCm70U?si=GWPm-1Or__uQB1u5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

*Image classification vs object detection* 

## Training an Image Classification Model

[Teachable Machine](https://teachablemachine.withgoogle.com/)

[Lee's Hands-on-Head demo of image recognition/classification](https://glitch.com/edit/#!/teachable-hands-on-head?path=README.md%3A1%3A0)

1. Collect Data 
 - Have 2 kinds of images of something
 - Label those images - (these are called "classes")
 - how many? - experiment. maybe 25 - 50 images per category.
2. Click *Train Model* and **Do not switch tabs** as it is training in the browser live!
 - This image classification is using MobileNet and a pretrained model (of a Convolutional Neural Network) to do Transfer Learning
3. When finished, test it. You can add more classes if you like (such as additional poses, or additional images).
4. It's good? Now we must save by clicking to *Export model*. Choose Tensorflow.js and choose to export to the Cloud. (In the future, if you don't want to upload your model to Google's server you could save locally). You will get a URL and a permanent webpage to use/test/debug/change your model.


### Example starter code 

[link](https://editor.p5js.org/2sman/sketches/rtSl0Xmkq)

1. Change your model url!
2. Edit your triggers.js file!

### Resources for Teachable Machine

- Sample javascript code on [github](https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image)
- Intro to Teachable Machine for Image Classification - [video](https://www.youtube.com/watch?v=kwcillcWOg0) on The Coding Train
- Tutorial on making a "Snake game" using gesture recognition - [video](https://www.youtube.com/watch?v=UPgxnGC8oBU) on The Coding Train

## Final Project: Speculative Interfaces 

##### requirements

> “Where typical design takes a look at small issues, speculative design broadens the scope and tries to tackle the biggest issues in society.” --Anthony Dunne and Fiona Raby, *Speculative Everything: Design, Fiction, and Social Dreaming*

Rather than look just at issues of today, speculative design thinking asks "How can we address future challenges with design?"

Propose a speculative user interface for an application. Throughout the course of the project you will propose a concept idea and design brief, create prototypes, test, and document and present.

Your idea can be practical or fanciful, surprising or challenging. It is an experimental interface, pointing forward to a new future.

Keep in mind our design and prototyping processes we've covered throughout the semester. You may have to improvise your own new approach for your speculative interface.

Consider our readings and learning from throughout the semester including but not limited to: the early history of early interface design, interface metaphors of the desktop, ergonomics, graphical interfaces, accessibility, voice control, speculative thinking. 

For next week, turn in a Design Brief including:
- a. concept stated in a short paragraph. How does it work? What is it for?
- b. list of sources - ideas, writing, concepts that are informing your design work (can also include science fiction, games, articles, movies)
- c. image references from these sources aka 'mood board' or inspiration
- d. sketches (paper/pen and/or digital)
- e. flowchart of interface - textual and/or visual
- f. list of resources (starter code, library, underlying technology)

###### References
- This is Not My Beautiful Home - [essay](http://continentcontinent.cc/index.php/continent/article/view/334) by Everest Pipkin
- What is Speculative Design? - [video](https://www.youtube.com/watch?v=X0MBJ1UxpZ8)
- Pointing to the future of UI - [video](https://www.youtube.com/watch?v=b6YTQJVzwlI)
- *Her* movie - Alien Child - speculative video game - [video](https://www.youtube.com/watch?v=XAqedT9mukY)
- Interfacing with devices through silent speech - [video](https://www.youtube.com/watch?v=RuUSc53Xpeg)
- Dynamicland Hardware Field trip - [video](https://www.youtube.com/watch?v=OQpr454yhvM)
- Virtual Reality Training for Operators - [video](https://www.youtube.com/watch?v=KYK6wuFaES8)

### Final deliverables 

1. Title
2. Concept Description of the interface
3. Practical description of how it works
4. Video OR images with text captions demonstrating a step-by-step walkthrough of your interface
